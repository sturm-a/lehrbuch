{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lineare und logistische Regression mit Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was ist Regression eigentlich ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kurz und knapp:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anhand der Regression lässt sich feststellen, ob sich durch eine Variable eine andere erklären lässt und ob es einen Zusammenhang zwischen diesen gibt. Ziel ist es dann, mithilfe der unabhängigen Variablen die abhängige Zielvariable vorherzusagen.\n",
    "Mögliche Fragestellungen einer Regression wären bspw:\n",
    "\n",
    "- Steigt die Armut bei Familien, wenn diese mehr Kinder haben ? \n",
    "\n",
    "- Sinkt die Anzahl der Temposünder, wenn man mehr Schilder aufstellt ?\n",
    "\n",
    "- Verbessert sich die Note einer Prüfung, wenn das Bestehen von Scheinaufgaben erforderlich sind für die Teilnahme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierbei wird die lineare Regression verwendet, wenn der Zusammenhang zwischen einer abhängigen Variable und einer oder mehreren unabhängigen Variablen ermittelt werden soll.\n",
    "Die logistische Regression findet ihren Einsatz, wenn der Zusammenhang zwischen einer abhängigen Variable die Binär ist und unabhängigen Variablen ermittelt werden soll."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineare Regression mit Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt mehrere Möglichkeiten, die lineare Regression in Python zu realisieren. Mann kann diese entweder mit numpy, scipy, statsmodel oder sckit-learn implementieren. In diesem Notebook werde ich die lineare Regression mithilfe des mächtigen Pythonmoduls scikit-learn erklären. \n",
    "Der Datensatz den ich verwenden werde, ist das Boston Housing Dataset (Quelle: UCI Machine Learning Repository). Der Datensatz enthält Daten zum Immobilienwert in den Vororten von Boston.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import und Aufbereitung der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst müssen die benötigten Pakete importiert werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz, den wir verwenden möchten, ist bereits im Modul sklearn vorhanden und muss deswegen einfach nur geladen werden. Den Datensatz wird anschließend im Objekt boston im Datentyp Dictionary gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Beschreibung des Datensatzes sehen wir, dass wir 13 unabhängige Variablen haben und eine abhängige Variable (MEDV). Die abhängige Variable wird auch Target genannt. Wir werden jetzt versuchen, mithilfe der 13 Variablen den Preis vorherzusagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = boston.DESCR\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst laden wir die Daten in ein Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4      5     6       7    8      9     10  \\\n",
       "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1  0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2  0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3  0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4  0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "\n",
       "       11    12  \n",
       "0  396.90  4.98  \n",
       "1  396.90  9.14  \n",
       "2  392.83  4.03  \n",
       "3  394.63  2.94  \n",
       "4  396.90  5.33  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos = pd.DataFrame(boston.data)\n",
    "bos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weil das Dataframe die Variablennamen noch nicht enthält, ersetzen wir die Nummerierung mit den Variablennamen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n",
       "0     0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900   1.0  296.0   \n",
       "1     0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671   2.0  242.0   \n",
       "2     0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671   2.0  242.0   \n",
       "3     0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622   3.0  222.0   \n",
       "4     0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622   3.0  222.0   \n",
       "5     0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622   3.0  222.0   \n",
       "6     0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605   5.0  311.0   \n",
       "7     0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505   5.0  311.0   \n",
       "8     0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821   5.0  311.0   \n",
       "9     0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921   5.0  311.0   \n",
       "10    0.22489  12.5   7.87   0.0  0.524  6.377   94.3  6.3467   5.0  311.0   \n",
       "11    0.11747  12.5   7.87   0.0  0.524  6.009   82.9  6.2267   5.0  311.0   \n",
       "12    0.09378  12.5   7.87   0.0  0.524  5.889   39.0  5.4509   5.0  311.0   \n",
       "13    0.62976   0.0   8.14   0.0  0.538  5.949   61.8  4.7075   4.0  307.0   \n",
       "14    0.63796   0.0   8.14   0.0  0.538  6.096   84.5  4.4619   4.0  307.0   \n",
       "15    0.62739   0.0   8.14   0.0  0.538  5.834   56.5  4.4986   4.0  307.0   \n",
       "16    1.05393   0.0   8.14   0.0  0.538  5.935   29.3  4.4986   4.0  307.0   \n",
       "17    0.78420   0.0   8.14   0.0  0.538  5.990   81.7  4.2579   4.0  307.0   \n",
       "18    0.80271   0.0   8.14   0.0  0.538  5.456   36.6  3.7965   4.0  307.0   \n",
       "19    0.72580   0.0   8.14   0.0  0.538  5.727   69.5  3.7965   4.0  307.0   \n",
       "20    1.25179   0.0   8.14   0.0  0.538  5.570   98.1  3.7979   4.0  307.0   \n",
       "21    0.85204   0.0   8.14   0.0  0.538  5.965   89.2  4.0123   4.0  307.0   \n",
       "22    1.23247   0.0   8.14   0.0  0.538  6.142   91.7  3.9769   4.0  307.0   \n",
       "23    0.98843   0.0   8.14   0.0  0.538  5.813  100.0  4.0952   4.0  307.0   \n",
       "24    0.75026   0.0   8.14   0.0  0.538  5.924   94.1  4.3996   4.0  307.0   \n",
       "25    0.84054   0.0   8.14   0.0  0.538  5.599   85.7  4.4546   4.0  307.0   \n",
       "26    0.67191   0.0   8.14   0.0  0.538  5.813   90.3  4.6820   4.0  307.0   \n",
       "27    0.95577   0.0   8.14   0.0  0.538  6.047   88.8  4.4534   4.0  307.0   \n",
       "28    0.77299   0.0   8.14   0.0  0.538  6.495   94.4  4.4547   4.0  307.0   \n",
       "29    1.00245   0.0   8.14   0.0  0.538  6.674   87.3  4.2390   4.0  307.0   \n",
       "..        ...   ...    ...   ...    ...    ...    ...     ...   ...    ...   \n",
       "476   4.87141   0.0  18.10   0.0  0.614  6.484   93.6  2.3053  24.0  666.0   \n",
       "477  15.02340   0.0  18.10   0.0  0.614  5.304   97.3  2.1007  24.0  666.0   \n",
       "478  10.23300   0.0  18.10   0.0  0.614  6.185   96.7  2.1705  24.0  666.0   \n",
       "479  14.33370   0.0  18.10   0.0  0.614  6.229   88.0  1.9512  24.0  666.0   \n",
       "480   5.82401   0.0  18.10   0.0  0.532  6.242   64.7  3.4242  24.0  666.0   \n",
       "481   5.70818   0.0  18.10   0.0  0.532  6.750   74.9  3.3317  24.0  666.0   \n",
       "482   5.73116   0.0  18.10   0.0  0.532  7.061   77.0  3.4106  24.0  666.0   \n",
       "483   2.81838   0.0  18.10   0.0  0.532  5.762   40.3  4.0983  24.0  666.0   \n",
       "484   2.37857   0.0  18.10   0.0  0.583  5.871   41.9  3.7240  24.0  666.0   \n",
       "485   3.67367   0.0  18.10   0.0  0.583  6.312   51.9  3.9917  24.0  666.0   \n",
       "486   5.69175   0.0  18.10   0.0  0.583  6.114   79.8  3.5459  24.0  666.0   \n",
       "487   4.83567   0.0  18.10   0.0  0.583  5.905   53.2  3.1523  24.0  666.0   \n",
       "488   0.15086   0.0  27.74   0.0  0.609  5.454   92.7  1.8209   4.0  711.0   \n",
       "489   0.18337   0.0  27.74   0.0  0.609  5.414   98.3  1.7554   4.0  711.0   \n",
       "490   0.20746   0.0  27.74   0.0  0.609  5.093   98.0  1.8226   4.0  711.0   \n",
       "491   0.10574   0.0  27.74   0.0  0.609  5.983   98.8  1.8681   4.0  711.0   \n",
       "492   0.11132   0.0  27.74   0.0  0.609  5.983   83.5  2.1099   4.0  711.0   \n",
       "493   0.17331   0.0   9.69   0.0  0.585  5.707   54.0  2.3817   6.0  391.0   \n",
       "494   0.27957   0.0   9.69   0.0  0.585  5.926   42.6  2.3817   6.0  391.0   \n",
       "495   0.17899   0.0   9.69   0.0  0.585  5.670   28.8  2.7986   6.0  391.0   \n",
       "496   0.28960   0.0   9.69   0.0  0.585  5.390   72.9  2.7986   6.0  391.0   \n",
       "497   0.26838   0.0   9.69   0.0  0.585  5.794   70.6  2.8927   6.0  391.0   \n",
       "498   0.23912   0.0   9.69   0.0  0.585  6.019   65.3  2.4091   6.0  391.0   \n",
       "499   0.17783   0.0   9.69   0.0  0.585  5.569   73.5  2.3999   6.0  391.0   \n",
       "500   0.22438   0.0   9.69   0.0  0.585  6.027   79.7  2.4982   6.0  391.0   \n",
       "501   0.06263   0.0  11.93   0.0  0.573  6.593   69.1  2.4786   1.0  273.0   \n",
       "502   0.04527   0.0  11.93   0.0  0.573  6.120   76.7  2.2875   1.0  273.0   \n",
       "503   0.06076   0.0  11.93   0.0  0.573  6.976   91.0  2.1675   1.0  273.0   \n",
       "504   0.10959   0.0  11.93   0.0  0.573  6.794   89.3  2.3889   1.0  273.0   \n",
       "505   0.04741   0.0  11.93   0.0  0.573  6.030   80.8  2.5050   1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "5       18.7  394.12   5.21  \n",
       "6       15.2  395.60  12.43  \n",
       "7       15.2  396.90  19.15  \n",
       "8       15.2  386.63  29.93  \n",
       "9       15.2  386.71  17.10  \n",
       "10      15.2  392.52  20.45  \n",
       "11      15.2  396.90  13.27  \n",
       "12      15.2  390.50  15.71  \n",
       "13      21.0  396.90   8.26  \n",
       "14      21.0  380.02  10.26  \n",
       "15      21.0  395.62   8.47  \n",
       "16      21.0  386.85   6.58  \n",
       "17      21.0  386.75  14.67  \n",
       "18      21.0  288.99  11.69  \n",
       "19      21.0  390.95  11.28  \n",
       "20      21.0  376.57  21.02  \n",
       "21      21.0  392.53  13.83  \n",
       "22      21.0  396.90  18.72  \n",
       "23      21.0  394.54  19.88  \n",
       "24      21.0  394.33  16.30  \n",
       "25      21.0  303.42  16.51  \n",
       "26      21.0  376.88  14.81  \n",
       "27      21.0  306.38  17.28  \n",
       "28      21.0  387.94  12.80  \n",
       "29      21.0  380.23  11.98  \n",
       "..       ...     ...    ...  \n",
       "476     20.2  396.21  18.68  \n",
       "477     20.2  349.48  24.91  \n",
       "478     20.2  379.70  18.03  \n",
       "479     20.2  383.32  13.11  \n",
       "480     20.2  396.90  10.74  \n",
       "481     20.2  393.07   7.74  \n",
       "482     20.2  395.28   7.01  \n",
       "483     20.2  392.92  10.42  \n",
       "484     20.2  370.73  13.34  \n",
       "485     20.2  388.62  10.58  \n",
       "486     20.2  392.68  14.98  \n",
       "487     20.2  388.22  11.45  \n",
       "488     20.1  395.09  18.06  \n",
       "489     20.1  344.05  23.97  \n",
       "490     20.1  318.43  29.68  \n",
       "491     20.1  390.11  18.07  \n",
       "492     20.1  396.90  13.35  \n",
       "493     19.2  396.90  12.01  \n",
       "494     19.2  396.90  13.59  \n",
       "495     19.2  393.29  17.60  \n",
       "496     19.2  396.90  21.14  \n",
       "497     19.2  396.90  14.10  \n",
       "498     19.2  396.90  12.92  \n",
       "499     19.2  395.77  15.10  \n",
       "500     19.2  396.90  14.33  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos.columns = boston.feature_names\n",
    "bos.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable die den Preis enthält ist in unserem Dataframe nicht zu finden. Wir holen die Preise aus boston.target und hängen sie dann an das Dataframe an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bos['PRICE'] = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lineare Regression mit Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Preise vorhersagen zu können, müssen wir nun ein lineares Regressionsmodel anpassen. Dazu verwenden wir die LinearRegression.fit Methode von Scikit. Dieser Methode müssen zwei Variablen übergeben werden, damit sie das Modell anpassen kann: \n",
    "\n",
    "- Y : Der Target (in diesem Fall der Preis)\n",
    "- X : Die unabhängige/n Variable/n (in diesem Fall wären dass die 13 übrigen Variablen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X = bos.drop('PRICE', axis = 1) # weil wir alle Variablen außer den Preis in X haben wollen\n",
    "\n",
    "# Hier erzeugen wir ein Objekt von LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X,bos.PRICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt können wir uns die mit der [KQ-Methode](https://www.wiwiweb.de/statistik/zeitreihenan/zeitverfahre/kleinstequad.html)  geschätzten Koeffizienten und die Konstante unserer Linearen Gleichung anzeigen lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.4911032804\n",
      "[ -1.07170557e-01   4.63952195e-02   2.08602395e-02   2.68856140e+00\n",
      "  -1.77957587e+01   3.80475246e+00   7.51061703e-04  -1.47575880e+00\n",
      "   3.05655038e-01  -1.23293463e-02  -9.53463555e-01   9.39251272e-03\n",
      "  -5.25466633e-01]\n"
     ]
    }
   ],
   "source": [
    "konstante = lr.intercept_\n",
    "koeffizienten = lr.coef_\n",
    "print(konstante)\n",
    "print(koeffizienten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur besseren Visualisierung unserer Konstanten erstellen wir einen Dataframe, wo wir an die 13 Variablen den Koeffizienten anhängen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CRIM', -0.10717055656035455),\n",
       " ('ZN', 0.046395219529801988),\n",
       " ('INDUS', 0.020860239532176736),\n",
       " ('CHAS', 2.688561399317893),\n",
       " ('NOX', -17.795758660309126),\n",
       " ('RM', 3.8047524602580109),\n",
       " ('AGE', 0.00075106170332306377),\n",
       " ('DIS', -1.4757587965198149),\n",
       " ('RAD', 0.3056550383391009),\n",
       " ('TAX', -0.012329346305271827),\n",
       " ('PTRATIO', -0.9534635546905541),\n",
       " ('B', 0.0093925127221892168),\n",
       " ('LSTAT', -0.52546663290079287)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame = list(zip(X.columns, lr.coef_))\n",
    "pd.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das gelernte Regressionsmodell ist also die lineare Gleichung:\n",
    "\n",
    "Preis = -0,11 CRIM 0,05 ZN 0,02 INDUS... -0,53 LSTAT +36,49\n",
    "\n",
    "Zudem sieht man nun, dass RM die höchste Korrelation zum Target besitzt. Das lässt sich mit einem Scatterplot mit RM und Preis noch besser verdeutlichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa8fd828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(bos.RM, bos.PRICE)\n",
    "plt.xlabel(\"RM\")\n",
    "plt.ylabel(\"Preis\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden wir den Preis vorhersagen. Um zu schauen, ob unser lineares Regressionsmodell gut genug ist, werden wir in einem Scatterplot die vorhergesagten Preise und die tatsächlichen Preise miteinander vergleichen. Mit der LinearRegression-Methode .predict lässt sich eine Vorhersage berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEOCAYAAACXX1DeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0sva15gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa8fda90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(bos.PRICE, lr.predict(X))\n",
    "plt.xlabel(\"Preis: $Y_i$\")\n",
    "plt.ylabel(\"Vorhergesagter Preis: $\\hat{Y}_i$\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier lässt sich jetzt unschwer erkennen, dass wir falsch geschätzte Werte haben im oberen Preissegment.\n",
    "\n",
    "Um die Qualität einer Regression zu bestimmen, kann man den MSE ([Mean squared error](https://www.wiwiweb.de/statistik/zeitreihenan/zeitverfahre/kleinstequad.html)) berechnen.\n",
    "Dieser gibt den quadrierten mittleren Abstand der geschätzten Werte von den tatsächlichen Werten an. Je höher der MSE ist, umso ungenauer ist die Vorhersage. Den MSE werden wir nun berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.8977792177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(bos.PRICE, lr.predict(X))\n",
    "print(mse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt werden wir ein lineares Regressionsmodell für nur eine Variable aufstellen und den MSE mit dem des Modells über die 13 Variablen vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.652200013769274"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf= LinearRegression()\n",
    "lf.fit(X[['PTRATIO']],bos.PRICE)\n",
    "mean_squared_error(bos.PRICE, lf.predict(X[['PTRATIO']]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der MSE hat sich mehr als verdoppelt, was bedeutet, dass eine Variable alleine keine gute Vorhersage machen kann. In einem Scatterplot, wo wir den Preis mithilfe des neuen Modells vorhersagen, sieht man noch deutlicher, wie ungenau diese Methode ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEOCAYAAACuOOGFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc738f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(bos.PRICE, lf.predict(X[['PTRATIO']]))\n",
    "plt.xlabel(\"Preis: $Y_i$\")\n",
    "plt.ylabel(\"Vorhergesagter Preis: $\\hat{Y}_i$\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training und Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell das wir gerade aufgebaut haben ist in der Form jedoch unbrauchbar, weil wir für die Erstellung des Modells die selben Daten verwendet haben, auf die wir das Modell dann angewendet haben für die Vorhersage des Preises.\n",
    "Normalerweise soll ein Modell auf neue Daten angewendet werden und dort möglichst genaue Prognosen erzielen.\n",
    "\n",
    "Aus diesem Grund wird der Datensatz ein einen Trainigsdatensatz und einen Testdatensatz gesplittet. Mit dem Trainingsdatensatz stellen wir unser Modell auf und am Testdatensatz sehen wir dann, wie gut unsere Regression ist.\n",
    "\n",
    "Theoretisch könnte man jetzt hergehen und den Boston-Datensatz einfach in der Mitte in Trainings- und Testdatensatz teilen. Das Problem, das daraus resultieren könnte, ist jedoch, dass man dann wahrscheinlich das Modell mit den billigen Immobilien aufstellt und dann an den teuren testet. Natürlich liegt auf der Hand, dass so ein Modell keine präzisen Vorhersagen treffen können wird. Deswegen ist es besser, die Unterteilung randomisiert vorzunehmen.\n",
    "\n",
    "Scikit enthält die Funktion train_test_split, die den Trainings- und Testdatensatz zufällig erzeugen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5240</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.04297</td>\n",
       "      <td>52.5</td>\n",
       "      <td>5.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>6.565</td>\n",
       "      <td>22.9</td>\n",
       "      <td>7.3172</td>\n",
       "      <td>6.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>371.72</td>\n",
       "      <td>9.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.13554</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4090</td>\n",
       "      <td>5.594</td>\n",
       "      <td>36.8</td>\n",
       "      <td>6.4980</td>\n",
       "      <td>4.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.37578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>5.404</td>\n",
       "      <td>88.6</td>\n",
       "      <td>3.6650</td>\n",
       "      <td>4.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>395.24</td>\n",
       "      <td>23.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.38214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5040</td>\n",
       "      <td>8.040</td>\n",
       "      <td>86.5</td>\n",
       "      <td>3.2157</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>387.38</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.08826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>6.417</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>383.73</td>\n",
       "      <td>6.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.01311</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4030</td>\n",
       "      <td>7.249</td>\n",
       "      <td>21.9</td>\n",
       "      <td>8.6966</td>\n",
       "      <td>5.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>395.93</td>\n",
       "      <td>4.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>4.34879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>6.167</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3.0334</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>16.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>14.43830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>6.852</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.4655</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>179.36</td>\n",
       "      <td>19.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1.41385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>6.129</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.7494</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>321.02</td>\n",
       "      <td>15.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.03049</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4840</td>\n",
       "      <td>6.874</td>\n",
       "      <td>28.1</td>\n",
       "      <td>6.4654</td>\n",
       "      <td>5.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>387.97</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.11460</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4640</td>\n",
       "      <td>6.538</td>\n",
       "      <td>58.7</td>\n",
       "      <td>3.9175</td>\n",
       "      <td>3.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>394.96</td>\n",
       "      <td>7.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2.63548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5440</td>\n",
       "      <td>4.973</td>\n",
       "      <td>37.8</td>\n",
       "      <td>2.5194</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>350.45</td>\n",
       "      <td>12.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.27346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6050</td>\n",
       "      <td>6.250</td>\n",
       "      <td>92.6</td>\n",
       "      <td>1.7984</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>338.92</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.47547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5440</td>\n",
       "      <td>6.113</td>\n",
       "      <td>58.8</td>\n",
       "      <td>4.0019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>396.23</td>\n",
       "      <td>12.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>9.51363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>6.728</td>\n",
       "      <td>94.1</td>\n",
       "      <td>2.4961</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>6.68</td>\n",
       "      <td>18.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.11747</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5240</td>\n",
       "      <td>6.009</td>\n",
       "      <td>82.9</td>\n",
       "      <td>6.2267</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>9.91655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>5.852</td>\n",
       "      <td>77.8</td>\n",
       "      <td>1.5004</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>338.16</td>\n",
       "      <td>29.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>28.65580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>5.155</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.5894</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>210.97</td>\n",
       "      <td>20.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.84054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.599</td>\n",
       "      <td>85.7</td>\n",
       "      <td>4.4546</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>303.42</td>\n",
       "      <td>16.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>73.53410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>5.957</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.8026</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>16.45</td>\n",
       "      <td>20.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2.14918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.709</td>\n",
       "      <td>98.5</td>\n",
       "      <td>1.6232</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>261.95</td>\n",
       "      <td>15.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.09849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>5.879</td>\n",
       "      <td>95.8</td>\n",
       "      <td>2.0063</td>\n",
       "      <td>2.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>379.38</td>\n",
       "      <td>17.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.12802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>6.474</td>\n",
       "      <td>97.1</td>\n",
       "      <td>2.4329</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>395.24</td>\n",
       "      <td>12.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.03113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4420</td>\n",
       "      <td>6.014</td>\n",
       "      <td>48.5</td>\n",
       "      <td>8.0136</td>\n",
       "      <td>3.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>385.64</td>\n",
       "      <td>10.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.21161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>6.137</td>\n",
       "      <td>87.4</td>\n",
       "      <td>2.7147</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>394.47</td>\n",
       "      <td>13.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.43571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>5.344</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.8750</td>\n",
       "      <td>4.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>23.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.88125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>5.637</td>\n",
       "      <td>94.7</td>\n",
       "      <td>1.9799</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>18.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>6.44405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5840</td>\n",
       "      <td>6.425</td>\n",
       "      <td>74.8</td>\n",
       "      <td>2.2004</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>97.95</td>\n",
       "      <td>12.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>5.836</td>\n",
       "      <td>91.9</td>\n",
       "      <td>2.2110</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>395.67</td>\n",
       "      <td>18.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.13262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>5.851</td>\n",
       "      <td>96.7</td>\n",
       "      <td>2.1069</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>394.05</td>\n",
       "      <td>16.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.19133</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>5.605</td>\n",
       "      <td>70.2</td>\n",
       "      <td>7.9549</td>\n",
       "      <td>7.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>389.13</td>\n",
       "      <td>18.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.29090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>6.174</td>\n",
       "      <td>93.6</td>\n",
       "      <td>1.6119</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>388.08</td>\n",
       "      <td>24.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>0.06724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>6.333</td>\n",
       "      <td>17.2</td>\n",
       "      <td>5.2146</td>\n",
       "      <td>4.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>375.21</td>\n",
       "      <td>7.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>10.06230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5840</td>\n",
       "      <td>6.833</td>\n",
       "      <td>94.3</td>\n",
       "      <td>2.0882</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>81.33</td>\n",
       "      <td>19.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2.15505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.628</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.5166</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>169.27</td>\n",
       "      <td>16.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.06129</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>7.645</td>\n",
       "      <td>49.7</td>\n",
       "      <td>5.2119</td>\n",
       "      <td>5.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>377.07</td>\n",
       "      <td>3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.19657</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>6.226</td>\n",
       "      <td>79.2</td>\n",
       "      <td>8.0555</td>\n",
       "      <td>7.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>376.14</td>\n",
       "      <td>10.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>8.20058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>5.936</td>\n",
       "      <td>80.3</td>\n",
       "      <td>2.7792</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>3.50</td>\n",
       "      <td>16.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>88.97620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6710</td>\n",
       "      <td>6.968</td>\n",
       "      <td>91.9</td>\n",
       "      <td>1.4165</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>17.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.11504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>6.163</td>\n",
       "      <td>69.6</td>\n",
       "      <td>3.4952</td>\n",
       "      <td>2.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>391.83</td>\n",
       "      <td>11.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>3.56868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>6.437</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.8965</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>393.37</td>\n",
       "      <td>14.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0.30347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4930</td>\n",
       "      <td>6.312</td>\n",
       "      <td>28.9</td>\n",
       "      <td>5.4159</td>\n",
       "      <td>5.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>6.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.20608</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>5.593</td>\n",
       "      <td>76.5</td>\n",
       "      <td>7.9549</td>\n",
       "      <td>7.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>372.49</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>5.09017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>6.297</td>\n",
       "      <td>91.8</td>\n",
       "      <td>2.3682</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>385.09</td>\n",
       "      <td>17.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>38.35180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>5.453</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.4896</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>30.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>24.80170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>5.349</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.7028</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>4.55587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>3.561</td>\n",
       "      <td>87.9</td>\n",
       "      <td>1.6132</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>354.70</td>\n",
       "      <td>7.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.14932</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4530</td>\n",
       "      <td>5.741</td>\n",
       "      <td>66.2</td>\n",
       "      <td>7.2254</td>\n",
       "      <td>8.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>395.11</td>\n",
       "      <td>13.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.09378</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5240</td>\n",
       "      <td>5.889</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.4509</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>390.50</td>\n",
       "      <td>15.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0.78570</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>7.014</td>\n",
       "      <td>84.6</td>\n",
       "      <td>2.1329</td>\n",
       "      <td>5.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>384.07</td>\n",
       "      <td>14.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>67.92080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>5.683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.4254</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>384.97</td>\n",
       "      <td>22.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>9.18702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>5.536</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.5804</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>23.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>45.74610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>4.519</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.6582</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>88.27</td>\n",
       "      <td>36.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.01778</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4030</td>\n",
       "      <td>7.135</td>\n",
       "      <td>13.9</td>\n",
       "      <td>7.6534</td>\n",
       "      <td>3.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>384.30</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2.36862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>4.926</td>\n",
       "      <td>95.7</td>\n",
       "      <td>1.4608</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>391.71</td>\n",
       "      <td>29.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>15.02340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>5.304</td>\n",
       "      <td>97.3</td>\n",
       "      <td>2.1007</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>349.48</td>\n",
       "      <td>24.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.14052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>6.375</td>\n",
       "      <td>32.3</td>\n",
       "      <td>3.9454</td>\n",
       "      <td>4.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>385.81</td>\n",
       "      <td>9.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.32543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>6.431</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8125</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>15.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM    ZN  INDUS  CHAS     NOX     RM    AGE     DIS   RAD    TAX  \\\n",
       "8     0.21124  12.5   7.87   0.0  0.5240  5.631  100.0  6.0821   5.0  311.0   \n",
       "289   0.04297  52.5   5.32   0.0  0.4050  6.565   22.9  7.3172   6.0  293.0   \n",
       "68    0.13554  12.5   6.07   0.0  0.4090  5.594   36.8  6.4980   4.0  345.0   \n",
       "211   0.37578   0.0  10.59   1.0  0.4890  5.404   88.6  3.6650   4.0  277.0   \n",
       "226   0.38214   0.0   6.20   0.0  0.5040  8.040   86.5  3.2157   8.0  307.0   \n",
       "70    0.08826   0.0  10.81   0.0  0.4130  6.417    6.6  5.2873   4.0  305.0   \n",
       "55    0.01311  90.0   1.22   0.0  0.4030  7.249   21.9  8.6966   5.0  226.0   \n",
       "470   4.34879   0.0  18.10   0.0  0.5800  6.167   84.0  3.0334  24.0  666.0   \n",
       "409  14.43830   0.0  18.10   0.0  0.5970  6.852  100.0  1.4655  24.0  666.0   \n",
       "154   1.41385   0.0  19.58   1.0  0.8710  6.129   96.0  1.7494   5.0  403.0   \n",
       "344   0.03049  55.0   3.78   0.0  0.4840  6.874   28.1  6.4654   5.0  370.0   \n",
       "272   0.11460  20.0   6.96   0.0  0.4640  6.538   58.7  3.9175   3.0  223.0   \n",
       "310   2.63548   0.0   9.90   0.0  0.5440  4.973   37.8  2.5194   4.0  304.0   \n",
       "160   1.27346   0.0  19.58   1.0  0.6050  6.250   92.6  1.7984   5.0  403.0   \n",
       "319   0.47547   0.0   9.90   0.0  0.5440  6.113   58.8  4.0019   4.0  304.0   \n",
       "454   9.51363   0.0  18.10   0.0  0.7130  6.728   94.1  2.4961  24.0  666.0   \n",
       "11    0.11747  12.5   7.87   0.0  0.5240  6.009   82.9  6.2267   5.0  311.0   \n",
       "399   9.91655   0.0  18.10   0.0  0.6930  5.852   77.8  1.5004  24.0  666.0   \n",
       "413  28.65580   0.0  18.10   0.0  0.5970  5.155  100.0  1.5894  24.0  666.0   \n",
       "25    0.84054   0.0   8.14   0.0  0.5380  5.599   85.7  4.4546   4.0  307.0   \n",
       "418  73.53410   0.0  18.10   0.0  0.6790  5.957  100.0  1.8026  24.0  666.0   \n",
       "153   2.14918   0.0  19.58   0.0  0.8710  5.709   98.5  1.6232   5.0  403.0   \n",
       "124   0.09849   0.0  25.65   0.0  0.5810  5.879   95.8  2.0063   2.0  188.0   \n",
       "108   0.12802   0.0   8.56   0.0  0.5200  6.474   97.1  2.4329   5.0  384.0   \n",
       "345   0.03113   0.0   4.39   0.0  0.4420  6.014   48.5  8.0136   3.0  352.0   \n",
       "103   0.21161   0.0   8.56   0.0  0.5200  6.137   87.4  2.7147   5.0  384.0   \n",
       "209   0.43571   0.0  10.59   1.0  0.4890  5.344  100.0  3.8750   4.0  277.0   \n",
       "129   0.88125   0.0  21.89   0.0  0.6240  5.637   94.7  1.9799   4.0  437.0   \n",
       "432   6.44405   0.0  18.10   0.0  0.5840  6.425   74.8  2.2004  24.0  666.0   \n",
       "106   0.17120   0.0   8.56   0.0  0.5200  5.836   91.9  2.2110   5.0  384.0   \n",
       "..        ...   ...    ...   ...     ...    ...    ...     ...   ...    ...   \n",
       "105   0.13262   0.0   8.56   0.0  0.5200  5.851   96.7  2.1069   5.0  384.0   \n",
       "245   0.19133  22.0   5.86   0.0  0.4310  5.605   70.2  7.9549   7.0  330.0   \n",
       "140   0.29090   0.0  21.89   0.0  0.6240  6.174   93.6  1.6119   4.0  437.0   \n",
       "329   0.06724   0.0   3.24   0.0  0.4600  6.333   17.2  5.2146   4.0  430.0   \n",
       "431  10.06230   0.0  18.10   0.0  0.5840  6.833   94.3  2.0882  24.0  666.0   \n",
       "146   2.15505   0.0  19.58   0.0  0.8710  5.628  100.0  1.5166   5.0  403.0   \n",
       "282   0.06129  20.0   3.33   1.0  0.4429  7.645   49.7  5.2119   5.0  216.0   \n",
       "247   0.19657  22.0   5.86   0.0  0.4310  6.226   79.2  8.0555   7.0  330.0   \n",
       "457   8.20058   0.0  18.10   0.0  0.7130  5.936   80.3  2.7792  24.0  666.0   \n",
       "380  88.97620   0.0  18.10   0.0  0.6710  6.968   91.9  1.4165  24.0  666.0   \n",
       "96    0.11504   0.0   2.89   0.0  0.4450  6.163   69.6  3.4952   2.0  276.0   \n",
       "1     0.02731   0.0   7.07   0.0  0.4690  6.421   78.9  4.9671   2.0  242.0   \n",
       "472   3.56868   0.0  18.10   0.0  0.5800  6.437   75.0  2.8965  24.0  666.0   \n",
       "326   0.30347   0.0   7.38   0.0  0.4930  6.312   28.9  5.4159   5.0  287.0   \n",
       "244   0.20608  22.0   5.86   0.0  0.4310  5.593   76.5  7.9549   7.0  330.0   \n",
       "452   5.09017   0.0  18.10   0.0  0.7130  6.297   91.8  2.3682  24.0  666.0   \n",
       "398  38.35180   0.0  18.10   0.0  0.6930  5.453  100.0  1.4896  24.0  666.0   \n",
       "403  24.80170   0.0  18.10   0.0  0.6930  5.349   96.0  1.7028  24.0  666.0   \n",
       "365   4.55587   0.0  18.10   0.0  0.7180  3.561   87.9  1.6132  24.0  666.0   \n",
       "60    0.14932  25.0   5.13   0.0  0.4530  5.741   66.2  7.2254   8.0  284.0   \n",
       "12    0.09378  12.5   7.87   0.0  0.5240  5.889   39.0  5.4509   5.0  311.0   \n",
       "266   0.78570  20.0   3.97   0.0  0.6470  7.014   84.6  2.1329   5.0  264.0   \n",
       "405  67.92080   0.0  18.10   0.0  0.6930  5.683  100.0  1.4254  24.0  666.0   \n",
       "382   9.18702   0.0  18.10   0.0  0.7000  5.536  100.0  1.5804  24.0  666.0   \n",
       "414  45.74610   0.0  18.10   0.0  0.6930  4.519  100.0  1.6582  24.0  666.0   \n",
       "200   0.01778  95.0   1.47   0.0  0.4030  7.135   13.9  7.6534   3.0  402.0   \n",
       "147   2.36862   0.0  19.58   0.0  0.8710  4.926   95.7  1.4608   5.0  403.0   \n",
       "477  15.02340   0.0  18.10   0.0  0.6140  5.304   97.3  2.1007  24.0  666.0   \n",
       "213   0.14052   0.0  10.59   0.0  0.4890  6.375   32.3  3.9454   4.0  277.0   \n",
       "128   0.32543   0.0  21.89   0.0  0.6240  6.431   98.8  1.8125   4.0  437.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "8       15.2  386.63  29.93  \n",
       "289     16.6  371.72   9.51  \n",
       "68      18.9  396.90  13.09  \n",
       "211     18.6  395.24  23.98  \n",
       "226     17.4  387.38   3.13  \n",
       "70      19.2  383.73   6.72  \n",
       "55      17.9  395.93   4.81  \n",
       "470     20.2  396.90  16.29  \n",
       "409     20.2  179.36  19.78  \n",
       "154     14.7  321.02  15.12  \n",
       "344     17.6  387.97   4.61  \n",
       "272     18.6  394.96   7.73  \n",
       "310     18.4  350.45  12.64  \n",
       "160     14.7  338.92   5.50  \n",
       "319     18.4  396.23  12.73  \n",
       "454     20.2    6.68  18.71  \n",
       "11      15.2  396.90  13.27  \n",
       "399     20.2  338.16  29.97  \n",
       "413     20.2  210.97  20.08  \n",
       "25      21.0  303.42  16.51  \n",
       "418     20.2   16.45  20.62  \n",
       "153     14.7  261.95  15.79  \n",
       "124     19.1  379.38  17.58  \n",
       "108     20.9  395.24  12.27  \n",
       "345     18.8  385.64  10.53  \n",
       "103     20.9  394.47  13.44  \n",
       "209     18.6  396.90  23.09  \n",
       "129     21.2  396.90  18.34  \n",
       "432     20.2   97.95  12.03  \n",
       "106     20.9  395.67  18.66  \n",
       "..       ...     ...    ...  \n",
       "105     20.9  394.05  16.47  \n",
       "245     19.1  389.13  18.46  \n",
       "140     21.2  388.08  24.16  \n",
       "329     16.9  375.21   7.34  \n",
       "431     20.2   81.33  19.69  \n",
       "146     14.7  169.27  16.65  \n",
       "282     14.9  377.07   3.01  \n",
       "247     19.1  376.14  10.15  \n",
       "457     20.2    3.50  16.94  \n",
       "380     20.2  396.90  17.21  \n",
       "96      18.0  391.83  11.34  \n",
       "1       17.8  396.90   9.14  \n",
       "472     20.2  393.37  14.36  \n",
       "326     19.6  396.90   6.15  \n",
       "244     19.1  372.49  12.50  \n",
       "452     20.2  385.09  17.27  \n",
       "398     20.2  396.90  30.59  \n",
       "403     20.2  396.90  19.77  \n",
       "365     20.2  354.70   7.12  \n",
       "60      19.7  395.11  13.15  \n",
       "12      15.2  390.50  15.71  \n",
       "266     13.0  384.07  14.79  \n",
       "405     20.2  384.97  22.98  \n",
       "382     20.2  396.90  23.60  \n",
       "414     20.2   88.27  36.98  \n",
       "200     17.0  384.30   4.45  \n",
       "147     14.7  391.71  29.53  \n",
       "477     20.2  349.48  24.91  \n",
       "213     18.6  385.81   9.38  \n",
       "128     21.2  396.90  15.39  \n",
       "\n",
       "[203 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_training, X_test, Y_training, Y_test = sklearn.cross_validation.train_test_split(\n",
    "X, bos.PRICE, test_size=0.4, random_state = 4)\n",
    "X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun stellen wir das Modell mit dem Trainingsdatensatz auf und machen auf dem Testdatensatz eine Vorhersage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = LinearRegression()\n",
    "lt.fit(X_training, Y_training)\n",
    "predicted = lt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt berechnen wir den MSE und vergleichen diesen mit dem des Modells über die gesamten Daten (21.8977792177)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.5721958732\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "mse = mean_squared_error(Y_test, predicted)\n",
    "print(mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der MSE ist nun höher als beim Modell über die gesamten Daten. Im Gegensatz zum MSE des ersten Ansatzes ist dieser jedoch gültig, da das Modell auf einem \"neuen\" Datensatz angewendet wurde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistische Regression mit Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt wo wir wissen, wie und wann man die lineare Regression anwendet, können wir uns der logistischen Regression widmen. \n",
    "Wie bereits erwähnt wird auch diese dafür verwendet, Korrelationen zwischen abhängigen und unabhängigen Variablen zu ermitteln und Vorhersagen zu treffen.\n",
    "Der Unterschied ist, dass die logistische Regression nur dann zum Einsatz kommt, wenn das Target (abhängige Variable) binär ist.\n",
    "\n",
    "Mithilfe von scikit-learn werden wir nochmal einen Datensatz analysieren und eine logistische Regression durchführen. Der Datensatz den wir benutzen werden ist das 'affairs dataset', welches in Statsmodels vorhanden ist und nur importiert werden muss. Es ist das Ergebnis einer Umfrage von verheirateten Frauen, welche über außereheliche Beziehungen befragt wurden.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der erste Schritt ist wieder das Importieren der benötigten Module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt laden wir das Dataset herunter. Es enthält 6366 Zeilen mit 9 Variablen: \n",
    "\n",
    "- rate_marriage: Bewertung der Ehe durch Ehefrau (1 = sehr schlecht, 5 = sehr gut)\n",
    "- age: Alter der Frau\n",
    "- yrs_married\n",
    "- children\n",
    "- religious: Selbständige Bewertung der Religiösität der Frau (1 = gar nicht, 4 sehr religös)\n",
    "- educ: Bildungsstand (9 = kein High-school Abschluss , 12 = High-school Abschluss, 14 = College, 16 = College Abschluss, 17 = Akademikerin, 20 = PhD etc.)\n",
    "- occupation: Beruf der Frau (1 = Schülerin/Studentin, 2 = Hilfsarbeiterin, 3 = Facharbeiterin, 4 = Lehrerin,Schriftstellerin,Krankenschwester..., 5 = Management, 6 = Vollakademikerin)\n",
    "- occupation_husb: Beruf des Ehemanns (selbe Codierung)\n",
    "- affairs: Dauer der außerehelichen Beziehungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dta = sm.datasets.fair.load_pandas().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate_marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>yrs_married</th>\n",
       "      <th>children</th>\n",
       "      <th>religious</th>\n",
       "      <th>educ</th>\n",
       "      <th>occupation</th>\n",
       "      <th>occupation_husb</th>\n",
       "      <th>affairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.666666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate_marriage   age  yrs_married  children  religious  educ  occupation  \\\n",
       "0            3.0  32.0          9.0       3.0        3.0  17.0         2.0   \n",
       "1            3.0  27.0         13.0       3.0        1.0  14.0         3.0   \n",
       "2            4.0  22.0          2.5       0.0        1.0  16.0         3.0   \n",
       "3            4.0  37.0         16.5       4.0        3.0  16.0         5.0   \n",
       "4            5.0  27.0          9.0       1.0        1.0  14.0         3.0   \n",
       "\n",
       "   occupation_husb   affairs  \n",
       "0              5.0  0.111111  \n",
       "1              4.0  3.230769  \n",
       "2              5.0  1.400000  \n",
       "3              5.0  0.727273  \n",
       "4              4.0  4.666666  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufbereitung der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser Target wird die binäre Variable 'affaere' sein, die wir noch erstellen müssen. 0 steht für keine Affäre und 1 für Affäre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta['affaere'] = (dta.affairs > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate_marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>yrs_married</th>\n",
       "      <th>children</th>\n",
       "      <th>religious</th>\n",
       "      <th>educ</th>\n",
       "      <th>occupation</th>\n",
       "      <th>occupation_husb</th>\n",
       "      <th>affairs</th>\n",
       "      <th>affaere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.230769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.666666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.666666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.852174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.826086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.799999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.266665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.041666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.266665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.361111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.826086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.826086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.041666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.839996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.545454</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.532609</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.799999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.187878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.199999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6336</th>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6337</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339</th>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6340</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6341</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6342</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6343</th>\n",
       "      <td>5.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6344</th>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6345</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6346</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6347</th>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6348</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6349</th>\n",
       "      <td>5.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6350</th>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6352</th>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6353</th>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6354</th>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6355</th>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6358</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6360</th>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6361</th>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362</th>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6363</th>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6364</th>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6365</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6366 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rate_marriage   age  yrs_married  children  religious  educ  occupation  \\\n",
       "0               3.0  32.0          9.0       3.0        3.0  17.0         2.0   \n",
       "1               3.0  27.0         13.0       3.0        1.0  14.0         3.0   \n",
       "2               4.0  22.0          2.5       0.0        1.0  16.0         3.0   \n",
       "3               4.0  37.0         16.5       4.0        3.0  16.0         5.0   \n",
       "4               5.0  27.0          9.0       1.0        1.0  14.0         3.0   \n",
       "5               4.0  27.0          9.0       0.0        2.0  14.0         3.0   \n",
       "6               5.0  37.0         23.0       5.5        2.0  12.0         5.0   \n",
       "7               5.0  37.0         23.0       5.5        2.0  12.0         2.0   \n",
       "8               3.0  22.0          2.5       0.0        2.0  12.0         3.0   \n",
       "9               3.0  27.0          6.0       0.0        1.0  16.0         3.0   \n",
       "10              2.0  27.0          6.0       2.0        1.0  16.0         3.0   \n",
       "11              5.0  27.0          6.0       2.0        3.0  14.0         3.0   \n",
       "12              3.0  37.0         16.5       5.5        1.0  12.0         2.0   \n",
       "13              5.0  27.0          6.0       0.0        2.0  14.0         3.0   \n",
       "14              4.0  22.0          6.0       1.0        1.0  14.0         4.0   \n",
       "15              4.0  37.0          9.0       2.0        2.0  14.0         3.0   \n",
       "16              4.0  27.0          6.0       1.0        1.0  12.0         3.0   \n",
       "17              1.0  37.0         23.0       5.5        4.0  14.0         5.0   \n",
       "18              2.0  42.0         23.0       2.0        2.0  20.0         4.0   \n",
       "19              4.0  37.0          6.0       0.0        2.0  16.0         5.0   \n",
       "20              5.0  22.0          2.5       0.0        2.0  14.0         3.0   \n",
       "21              3.0  37.0         16.5       5.5        2.0   9.0         3.0   \n",
       "22              3.0  42.0         23.0       5.5        3.0  12.0         5.0   \n",
       "23              2.0  27.0          9.0       2.0        4.0  20.0         3.0   \n",
       "24              4.0  27.0          6.0       1.0        2.0  12.0         5.0   \n",
       "25              5.0  27.0          2.5       0.0        3.0  16.0         4.0   \n",
       "26              2.0  27.0          6.0       2.0        2.0  12.0         2.0   \n",
       "27              5.0  37.0         13.0       1.0        3.0  12.0         3.0   \n",
       "28              2.0  32.0         16.5       2.0        2.0  12.0         4.0   \n",
       "29              3.0  27.0          6.0       1.0        1.0  14.0         3.0   \n",
       "...             ...   ...          ...       ...        ...   ...         ...   \n",
       "6336            5.0  42.0         23.0       4.0        3.0  14.0         5.0   \n",
       "6337            5.0  27.0          6.0       0.0        4.0  14.0         4.0   \n",
       "6338            5.0  42.0         23.0       2.0        3.0  12.0         2.0   \n",
       "6339            4.0  32.0         13.0       3.0        3.0  16.0         4.0   \n",
       "6340            5.0  27.0         13.0       3.0        3.0  16.0         4.0   \n",
       "6341            5.0  27.0          9.0       1.0        2.0  14.0         4.0   \n",
       "6342            4.0  22.0          2.5       0.0        2.0  16.0         4.0   \n",
       "6343            5.0  17.5          2.5       0.0        4.0  12.0         3.0   \n",
       "6344            4.0  32.0         16.5       2.0        2.0  12.0         3.0   \n",
       "6345            5.0  27.0          9.0       1.0        3.0  12.0         3.0   \n",
       "6346            4.0  22.0          2.5       0.0        4.0  14.0         4.0   \n",
       "6347            5.0  22.0          2.5       1.0        2.0  12.0         3.0   \n",
       "6348            5.0  27.0          0.5       0.0        4.0  20.0         4.0   \n",
       "6349            5.0  37.0         16.5       3.0        3.0  14.0         5.0   \n",
       "6350            5.0  32.0         13.0       2.0        4.0  14.0         3.0   \n",
       "6351            4.0  22.0          0.5       0.0        2.0  16.0         3.0   \n",
       "6352            5.0  42.0         23.0       2.0        4.0  12.0         3.0   \n",
       "6353            5.0  22.0          2.5       2.0        2.0  14.0         3.0   \n",
       "6354            5.0  42.0         23.0       4.0        4.0  12.0         3.0   \n",
       "6355            4.0  27.0          6.0       0.0        3.0  12.0         3.0   \n",
       "6356            5.0  32.0         13.0       3.0        3.0  12.0         3.0   \n",
       "6357            5.0  32.0         13.0       4.0        2.0  14.0         4.0   \n",
       "6358            3.0  27.0          6.0       2.0        4.0  14.0         3.0   \n",
       "6359            4.0  22.0          2.5       0.0        3.0  16.0         5.0   \n",
       "6360            5.0  22.0          2.5       0.0        2.0  14.0         3.0   \n",
       "6361            5.0  32.0         13.0       2.0        3.0  17.0         4.0   \n",
       "6362            4.0  32.0         13.0       1.0        1.0  16.0         5.0   \n",
       "6363            5.0  22.0          2.5       0.0        2.0  14.0         3.0   \n",
       "6364            5.0  32.0          6.0       1.0        3.0  14.0         3.0   \n",
       "6365            4.0  22.0          2.5       0.0        2.0  16.0         2.0   \n",
       "\n",
       "      occupation_husb    affairs  affaere  \n",
       "0                 5.0   0.111111        1  \n",
       "1                 4.0   3.230769        1  \n",
       "2                 5.0   1.400000        1  \n",
       "3                 5.0   0.727273        1  \n",
       "4                 4.0   4.666666        1  \n",
       "5                 4.0   4.666666        1  \n",
       "6                 4.0   0.852174        1  \n",
       "7                 3.0   1.826086        1  \n",
       "8                 3.0   4.799999        1  \n",
       "9                 5.0   1.333333        1  \n",
       "10                5.0   3.266665        1  \n",
       "11                5.0   2.041666        1  \n",
       "12                3.0   0.484848        1  \n",
       "13                2.0   2.000000        1  \n",
       "14                4.0   3.266665        1  \n",
       "15                6.0   1.361111        1  \n",
       "16                5.0   2.000000        1  \n",
       "17                2.0   1.826086        1  \n",
       "18                4.0   1.826086        1  \n",
       "19                4.0   2.041666        1  \n",
       "20                4.0   7.839996        1  \n",
       "21                2.0   2.545454        1  \n",
       "22                4.0   0.532609        1  \n",
       "23                4.0   0.622222        1  \n",
       "24                4.0   0.583333        1  \n",
       "25                1.0   4.799999        1  \n",
       "26                5.0   0.166667        1  \n",
       "27                4.0   0.615385        1  \n",
       "28                2.0   1.187878        1  \n",
       "29                6.0  11.199999        1  \n",
       "...               ...        ...      ...  \n",
       "6336              4.0   0.000000        0  \n",
       "6337              4.0   0.000000        0  \n",
       "6338              2.0   0.000000        0  \n",
       "6339              2.0   0.000000        0  \n",
       "6340              2.0   0.000000        0  \n",
       "6341              5.0   0.000000        0  \n",
       "6342              1.0   0.000000        0  \n",
       "6343              5.0   0.000000        0  \n",
       "6344              4.0   0.000000        0  \n",
       "6345              5.0   0.000000        0  \n",
       "6346              2.0   0.000000        0  \n",
       "6347              2.0   0.000000        0  \n",
       "6348              4.0   0.000000        0  \n",
       "6349              5.0   0.000000        0  \n",
       "6350              6.0   0.000000        0  \n",
       "6351              1.0   0.000000        0  \n",
       "6352              2.0   0.000000        0  \n",
       "6353              5.0   0.000000        0  \n",
       "6354              5.0   0.000000        0  \n",
       "6355              4.0   0.000000        0  \n",
       "6356              5.0   0.000000        0  \n",
       "6357              4.0   0.000000        0  \n",
       "6358              1.0   0.000000        0  \n",
       "6359              5.0   0.000000        0  \n",
       "6360              3.0   0.000000        0  \n",
       "6361              3.0   0.000000        0  \n",
       "6362              5.0   0.000000        0  \n",
       "6363              1.0   0.000000        0  \n",
       "6364              4.0   0.000000        0  \n",
       "6365              4.0   0.000000        0  \n",
       "\n",
       "[6366 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor wir das Regressionsmodell aufstellen, bereiten wir unsere Daten etwas auf. Die Variablen 'occupation' und 'occupation_husb' werden wir als kategorische Variablen betrachten. Mit der Funktion dmatrices lässt sich das implementieren.\n",
    "\n",
    "Zudem definieren wir mit der Funktion dmatrices 'affaere' als Y und die restlichen Variablen mit Ausnahme von 'affairs' und 'affaere' als X.\n",
    "\n",
    "Zur besseren Visualisierung vergeben wir in diesem Schritt auch noch neue Namen für die neu erstellten kategorischen Variablen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Intercept', 'occ_2', 'occ_3', 'occ_4', 'occ_5', 'occ_6', 'occ_husb_2',\n",
      "       'occ_husb_3', 'occ_husb_4', 'occ_husb_5', 'occ_husb_6', 'rate_marriage',\n",
      "       'age', 'yrs_married', 'children', 'religious', 'educ'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('affaere ~ rate_marriage + age + yrs_married + children + \\\n",
    "                  religious + educ + C(occupation) + C(occupation_husb)',\n",
    "                  dta, return_type=\"dataframe\")\n",
    "y = np.ravel(y) # y machen wir zu einem 1-dimensionalen Array, damit es als Target von Scikit-learn richtig erkannt wird\n",
    "\n",
    "X = X.rename(columns = {'C(occupation)[T.2.0]':'occ_2',\n",
    "                        'C(occupation)[T.3.0]':'occ_3',\n",
    "                        'C(occupation)[T.4.0]':'occ_4',\n",
    "                        'C(occupation)[T.5.0]':'occ_5',\n",
    "                        'C(occupation)[T.6.0]':'occ_6',\n",
    "                        'C(occupation_husb)[T.2.0]':'occ_husb_2',\n",
    "                        'C(occupation_husb)[T.3.0]':'occ_husb_3',\n",
    "                        'C(occupation_husb)[T.4.0]':'occ_husb_4',\n",
    "                        'C(occupation_husb)[T.5.0]':'occ_husb_5',\n",
    "                        'C(occupation_husb)[T.6.0]':'occ_husb_6'})\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufstellen des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir das logistische Regressionsmodell aufstellen. Wie vorhin werden wir dieses zuerst über den ganzen Datensatz aufstellen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodell = LogisticRegression()\n",
    "logmodell = logmodell.fit(X, y)\n",
    "pred_log = logmodell.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt schauen wir uns an, wie genau unsere Regression ist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27411247251021048"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "mse = mean_squared_error(y, pred_log)\n",
    "mse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training und Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie wir aber bereits bei der linearen Regression gelernt haben, ist dieser Wert ungültig, weil das Modell auf den selben Daten aufgestellt wurde, auf die es angewendet wurde. \n",
    "\n",
    "Um einen gültigen Wert zu erzielen, müssen wir wieder die Methode mit dem Trainings- und Testdatensatz anwenden. Wir splitten den Datensatz wieder mit der Funktion train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.270157068063\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logmodell2 = LogisticRegression()\n",
    "logmodell2.fit(X_train, y_train)\n",
    "pred_log = logmodell2.predict(X_test)\n",
    "mse = mean_squared_error(y_test, pred_log)\n",
    "print(mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Fall ist das Modell genauso präzise wie das Modell über die ganzen Daten. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Außer den MSE gibt es noch eine weitere Möglichkeit die Genauigkeit eines Modells festzustellen. Scikit-learn bietet die Funktion .score an, die die mittlere Genauigkeit der vorhergesagten Werte angibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72573044297832234"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodell2.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Genauigkeit der Vorhersagen liegt bei 72 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting/Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bisher haben wir den Datensatz jeweils in einen Test- und einen Trainingsdatensatz gesplittet. Diese Methode ist zwar zulässig, birgt jedoch die erhöhte Gefahr, dass man entweder overfittet oder underfittet, was beides vermieden werden sollte, weil darunter die Genauigkeit der Prognosen leidet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitted ist ein Modell, wenn es \"zu gut\" am Trainingsdatensatz trainiert wurde. Das heißt dann, dass es am Trainingsdatensatz zwar sehr gute Prognosen liefern kann, an neuen Daten jedoch kläglich scheitert.\n",
    "Overfitting kann auftreten, wenn bspw. zuviele Variablen als Feature verwendet werden oder wenn diese im Verhältnis zu den Beobachtungen im Trainigsdatensatz zuviele sind. Trainiert man auf so einem Datensatz, lernt das Modell nicht die Beziehungen zwischen Target und Features, sondern beschreibt eher die Varianz der Variablen. Da die Werte jedoch in einem neuen Datensatz anders variieren, kann die getroffene Prognose keine gute sein. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underfitting ist sozusagen das Gegenteil vom Overfitting. Hier ist das Modell \"zu schlecht\" am Trainingsset trainiert worden. Das passiert, wenn es zuwenige Features gibt oder wenn wir die lineare Regression auf nicht lineare Daten anwenden. Ein Modell welches underfittet ist, prognostiziert sowohl auf dem Trainingsset, als auch auf neuen Daten sehr schlecht.\n",
    "\n",
    "Underfitting kommt nicht so häufig vor. Was viel häufiger vorkommt ist das Overfitting. \n",
    "Auch bei unserem Datensatz könnte sowas passieren, wenn wir nur in Training und Test splitten.\n",
    "Was z.B. passieren könnte ist, dass der zufällig gesplittete Datensatz zufällig fast nur aus älteren Frauen besteht. Wenn so ein Modell dann auf neue Daten mit hauptsächlich jüngeren Frauen losgelassen wird, sind die Ergebnisse natürlich nicht gut. Um dem möglichst entgegen zu wirken, gibt es die sogenannte x-fache Kreuzvalidierung.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### x-fache Kreuzvalidierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der x-fachen Kreuzvalidierung wird der Datensatz nicht wie wir es vorhin gemacht haben nur in in einen Test und Trainings Datensatz gesplittet, sondern in x Datensätze, wobei sich x typischerweise im Bereich 4-10 bewegt. In x Iterationen wird dann jeweils ein Datensatz als Testdatensatz festgelegt und x-1 zum Trainieren. Wenn das ganze x mal gemacht worden ist, wird der Durchschnitt davon gebildet, der dann das Modell darstellt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Methode werden wir jetzt an unserem Datensatz anwenden und schauen uns den Score an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7241630685514876"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
    "scores\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben wieder eine Genauigkeit von 73%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prognose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um uns vor Augen zu bringen, was man mit diesem Modell anstellen kann, werden wir nun die Wahrscheinlichkeit vorhersagen, dass eine fiktive Studienteilnehmerin eine außereheliche Beziehung hat. Die fiktive Frau ist eine 60 Jahre alte Lehrerin, die seit 30 Jahren verheiratet ist, 3 Kinder hat, religiös ist, ihre Ehe als sehr gut bezeichnet und mit einem Landwirt verheiratet ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.24710507,  0.75289493]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodell2.predict_proba(np.array([1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 60, 30, 3, 4,\n",
    "                              16]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Wahrscheinlichkeit, dass sich besagte fiktive Frau schonmal einen Fehltritt in der Ehe geleistet hat, liegt mit 72%-Wahrscheinlichkeit bei 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quellen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://medium.com/towards-data-science/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "- http://scikit-learn.org/stable/documentation.html \n",
    "- https://de.wikipedia.org/wiki/Regressionsanalyse\n",
    "- https://en.wikipedia.org/wiki/Linear_regression\n",
    "- https://en.wikipedia.org/wiki/Logistic_regression\n",
    "- http://www.dataschool.io/logistic-regression-in-python-using-scikit-learn/\n",
    "- https://www.hdm-stuttgart.de/~maucher/Python/SklearnIntro/html/dataminingSklearn.html\n",
    "- http://bigdata-madesimple.com/how-to-run-linear-regression-in-python-scikit-learn/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
